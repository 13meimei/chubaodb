## 操作顺序
考虑一个raft组，初始时组内有三个节点，node id 分别为 1， 2 和 3.
我们有时候需要先把节点3从组内删除，随后又在节点3上重新启动一个新的raft加入原来的组内。
在加入时，需要严格遵守先调用ChangeMember接口添加raft成员并且等待命令commit成功后，再启动节点3上的raft。否则可能会有数据丢失的风险。

这是因为有以下一种特殊场景的存在：
假设初始时1、2、3三个节点1是Leader，此时我们向1提交删除成员3的命令（假设对应的日志index=10），但节点2可能暂时存在故障，它的日志只复制到index=5的位置。删除命令只复制给1，3节点，属于大多数，删除3成功。随后我们又在3节点上重新启动了一个新的raft，新raft的日志是空的。
然后节点2发起选举，注意此时节点2认为集群的成员还是初始时的1，2，3，它比3节点的新raft日志新，可以选为leader，导致一个最新日志index=5的节点成为集群leader，index=5之后的日志有可能被截断丢失。

出现这种状况的原因在于raft论文讨论成员变更删除又添加一个成员时，都是删除2，添加3，是不同节点id。同一个节点id的话，成员变更和新节点启动需要有上面的顺序约束。这是multiraft下的一个特殊问题，单raft的话新加入的节点可以新的id来安全地避免这个问题。

## PeerID
`proto.Peer`结构中的PeerID成员表示全局唯一的副本ID，不同group的副本PeerID不一样，同group内的不同副本PeerID也不一样。

PeerID的引入是为了解决node rejoin时，新raft同步旧日志时有可能把之前删除同node上旧raft的命令同步过来并应用，导致新的raft被错误删除的问题。有了PeerID，同node上的新旧raft PeerID不一样，可以区分出来，避免错误删除。




